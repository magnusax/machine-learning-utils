{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.1.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Keras imports\n",
    "import keras\n",
    "print(\"Keras version: %s\" % keras.__version__)\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load some toy data to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000, 28 * 28))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "x_test = x_test.reshape((10000, 28 * 28))\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us build a simple deep neural network in order to establish a baseline. \n",
    "\n",
    "The best result I have gotten using a classical model (random ensembling of a tuned `GradientBoostingClassifier`) is $98.7\\%$. Let's try to beat that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(int(28*28),)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "opt = RMSprop(lr=0.01)\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.4285 - acc: 0.8716 - val_loss: 0.2030 - val_acc: 0.9460\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 4s 80us/step - loss: 0.2286 - acc: 0.9350 - val_loss: 0.1352 - val_acc: 0.9623\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1831 - acc: 0.9474 - val_loss: 0.1265 - val_acc: 0.9654\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1611 - acc: 0.9552 - val_loss: 0.1555 - val_acc: 0.9560\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1446 - acc: 0.9592 - val_loss: 0.1101 - val_acc: 0.9716\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1366 - acc: 0.9616 - val_loss: 0.1190 - val_acc: 0.9689\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1290 - acc: 0.9647 - val_loss: 0.1055 - val_acc: 0.9733\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1245 - acc: 0.9657 - val_loss: 0.0998 - val_acc: 0.9742\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1170 - acc: 0.9681 - val_loss: 0.1049 - val_acc: 0.9739\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1183 - acc: 0.9680 - val_loss: 0.1023 - val_acc: 0.9742\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 4s 81us/step - loss: 0.1141 - acc: 0.9694 - val_loss: 0.0964 - val_acc: 0.9776\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 4s 82us/step - loss: 0.1119 - acc: 0.9703 - val_loss: 0.1015 - val_acc: 0.9753\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1074 - acc: 0.9723 - val_loss: 0.0987 - val_acc: 0.9768\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 6s 117us/step - loss: 0.1114 - acc: 0.9710 - val_loss: 0.1325 - val_acc: 0.9737\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1040 - acc: 0.9718 - val_loss: 0.1165 - val_acc: 0.9763\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.1033 - acc: 0.9730 - val_loss: 0.0985 - val_acc: 0.9778\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1059 - acc: 0.9727 - val_loss: 0.1011 - val_acc: 0.9770\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1019 - acc: 0.9739 - val_loss: 0.1158 - val_acc: 0.9755\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1012 - acc: 0.9745 - val_loss: 0.0974 - val_acc: 0.9787\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.1013 - acc: 0.9749 - val_loss: 0.0995 - val_acc: 0.9790\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.1034 - acc: 0.9745 - val_loss: 0.0986 - val_acc: 0.9776\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.0978 - acc: 0.9755 - val_loss: 0.0971 - val_acc: 0.9779\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.0989 - acc: 0.9755 - val_loss: 0.1113 - val_acc: 0.9757\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.0966 - acc: 0.9760 - val_loss: 0.1237 - val_acc: 0.9774\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.0976 - acc: 0.9760 - val_loss: 0.1029 - val_acc: 0.9774\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.0939 - acc: 0.9764 - val_loss: 0.1052 - val_acc: 0.9784\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.0926 - acc: 0.9782 - val_loss: 0.1120 - val_acc: 0.9782\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.0888 - acc: 0.9780 - val_loss: 0.1192 - val_acc: 0.9761\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0918 - acc: 0.9781 - val_loss: 0.1151 - val_acc: 0.9787\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 4s 92us/step - loss: 0.0907 - acc: 0.9782 - val_loss: 0.1081 - val_acc: 0.9772\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.0955 - acc: 0.9767 - val_loss: 0.1070 - val_acc: 0.9780\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.0890 - acc: 0.9792 - val_loss: 0.1129 - val_acc: 0.9798\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.0880 - acc: 0.9797 - val_loss: 0.1185 - val_acc: 0.9796\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.0860 - acc: 0.9798 - val_loss: 0.1182 - val_acc: 0.9798\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.0910 - acc: 0.9790 - val_loss: 0.1078 - val_acc: 0.9780\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.0893 - acc: 0.9800 - val_loss: 0.1385 - val_acc: 0.9762\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.0908 - acc: 0.9791 - val_loss: 0.1044 - val_acc: 0.9782\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.0874 - acc: 0.9795 - val_loss: 0.1007 - val_acc: 0.9795\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.0890 - acc: 0.9800 - val_loss: 0.1041 - val_acc: 0.9777\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 4s 94us/step - loss: 0.0834 - acc: 0.9803 - val_loss: 0.1201 - val_acc: 0.9789\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.0834 - acc: 0.9814 - val_loss: 0.1169 - val_acc: 0.9794\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.0818 - acc: 0.9814 - val_loss: 0.1226 - val_acc: 0.9786\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.0920 - acc: 0.9810 - val_loss: 0.1086 - val_acc: 0.9787\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0906 - acc: 0.9795 - val_loss: 0.1035 - val_acc: 0.9814\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 4s 83us/step - loss: 0.0843 - acc: 0.9801 - val_loss: 0.1033 - val_acc: 0.9810\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0872 - acc: 0.9804 - val_loss: 0.1099 - val_acc: 0.9800\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 4s 84us/step - loss: 0.0833 - acc: 0.9812 - val_loss: 0.1263 - val_acc: 0.9780\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.0872 - acc: 0.9811 - val_loss: 0.1197 - val_acc: 0.9757\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.0899 - acc: 0.9808 - val_loss: 0.1085 - val_acc: 0.9794\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.0876 - acc: 0.9817 - val_loss: 0.1277 - val_acc: 0.9806\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=n_epochs, verbose=1, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = range(1, n_epochs+1)\n",
    "train_accuracy = history.history['acc']\n",
    "val_accuracy = history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAADTCAYAAACSliTcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzjkXyv8DcXhrXczU5M8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4fa767f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,3))\n",
    "# b+ is for \"blue cross\"\n",
    "plt.plot(epochs, train_accuracy, 'b-', label='Training')\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, val_accuracy, 'b--', label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 50us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11428790342416423, 0.98129999999999995]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((60000, 28, 28, 1))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D((2, 2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(64, activation='relu'))\n",
    "cnn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = RMSprop()\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "cnn.compile(optimizer=opt, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.1725 - acc: 0.9453\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0484 - acc: 0.9849\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 29s 490us/step - loss: 0.0336 - acc: 0.9896\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 0.0245 - acc: 0.9926\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.0194 - acc: 0.9940\n"
     ]
    }
   ],
   "source": [
    "cnn_hist = cnn.fit(x_train, y_train, epochs=5, verbose=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 184us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.028136635534705783, 0.99170000000000003]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation on the \"dogscats\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = load_img('keras/data/samples/cat.0.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "# the .flow() command below generates batches of randomly transformed images\n",
    "# and saves the results to the `preview/` directory\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1,\n",
    "                          save_to_dir='preview', \n",
    "                          save_prefix='cat', \n",
    "                          save_format='jpeg'):\n",
    "    i += 1\n",
    "    if i > 20: break  # otherwise the generator would loop indefinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11493, 11500)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob, shutil\n",
    "cat_files = glob.glob('keras/data/train/cat.*.jpg', recursive=True)\n",
    "dog_files = glob.glob('keras/data/train/dog.*.jpg', recursive=True)\n",
    "len(cat_files), len(dog_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Sample 500 from each class and later move to validation folder\n",
    "cat_files_random = np.random.choice(cat_files, size=500, replace=False)\n",
    "dog_files_random = np.random.choice(dog_files, size=500, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Move files!\n",
    "\n",
    "cat_destination = \"keras/data/validation/cats/\"\n",
    "for filename in cat_files_random:\n",
    "    shutil.move(filename, cat_destination)\n",
    "    \n",
    "dog_destination = \"keras/data/validation/dogs/\" \n",
    "for filename in dog_files_random:\n",
    "    shutil.move(filename, dog_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'keras/data/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # since we use binary_crossentropy loss, we need binary labels\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'keras/data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 49s 390ms/step - loss: 0.7476 - acc: 0.5180 - val_loss: 0.6760 - val_acc: 0.6338\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 48s 383ms/step - loss: 0.6811 - acc: 0.5690 - val_loss: 0.6543 - val_acc: 0.5850\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 48s 382ms/step - loss: 0.6581 - acc: 0.6155 - val_loss: 0.6099 - val_acc: 0.6637\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 47s 373ms/step - loss: 0.6434 - acc: 0.6600 - val_loss: 0.6218 - val_acc: 0.6675\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 47s 373ms/step - loss: 0.6193 - acc: 0.6745 - val_loss: 0.7292 - val_acc: 0.6525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3c6630>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1000 // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('keras/first_try.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
